name: LinkedIn Job Scraper

on:
  schedule:
    # Runs every 10 minutes
    - cron: '*/10 * * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Download previous job history
      uses: actions/download-artifact@v4
      with:
        name: job-history
        path: ./
      continue-on-error: true
      
    - name: Check if job history exists
      run: |
        if [ -f previous_jobs.json ]; then
          echo "âœ… Job history file found: $(wc -l < previous_jobs.json) lines"
          echo "ðŸ“„ File size: $(du -h previous_jobs.json)"
        else
          echo "ðŸ“„ No previous job history found - this will be the first run"
          echo "[]" > previous_jobs.json
        fi
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run LinkedIn job scraper
      env:
        EMAIL_TO: ${{ secrets.EMAIL_TO }}
        EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      run: |
        python Linkedin.py
        
    - name: Check job history after run
      run: |
        if [ -f previous_jobs.json ]; then
          echo "âœ… Job history after run: $(wc -l < previous_jobs.json) lines"
          echo "ðŸ“„ File size after run: $(du -h previous_jobs.json)"
        else
          echo "âŒ No job history file created!"
        fi
        
    - name: Upload job history (persist between runs)
      uses: actions/upload-artifact@v4
      with:
        name: job-history
        path: previous_jobs.json
        retention-days: 30
      if: always()  # Upload even if previous steps failed 
